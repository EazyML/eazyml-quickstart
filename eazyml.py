# TODO changes to be done:
# 1. make REST request headers same in all functions

import requests
import json
import traceback
import configparser
import os
import pandas as pd
import io


# read config file
EAZYML_URL = None
config = configparser.ConfigParser()
config.read('config.ini')
config_error_message = "Unable to load EazML Client Library. " \
                       "Please set the EAZYML_URL in config.ini"
try:
    EAZYML_URL = config.get("URL", "EAZYML_URL")
    if not EAZYML_URL:
        print(config_error_message)
        exit()
except configparser.NoOptionError as e:
    print(config_error_message, e)
    exit()

API_URL = EAZYML_URL.rstrip("/") + "/ez_api"


def exception_return(e, status_code):
    return_response = {"success": False, "status_code": status_code}
    try:
        raise(e)
    except requests.exceptions.HTTPError as errh:
        message = errh
    except requests.exceptions.Timeout as errto:
        message = "Connection timeout", errto
    except requests.exceptions.TooManyRedirects as errtr:
        message = "Too many redirects", errtr
    except requests.exceptions.ConnectionError as errce:
        message = "Connection error", errce
    except requests.exceptions.RequestException as errre:
        message = "Connection error", errre
    except Exception as erre:
        message = "Exception", erre
    return_response["message"] = message
    return return_response


def ez_auth(username, password=None, api_key=None):
    """EazyML Authorization Function

    Parameters
    ----------
    username : type 'str'
        The username
    password : type 'str'
        Password for the username

    Returns
    -------
    return_response: type 'dict'
                    {
                     "success"     : <False|True>,
                     "token"       : <None|string_token>
                     "status_code" : <None|string_token>
                     "message"     : <None|string_token>
                    }
        The return dictionary will set success to True and update
        token if authentication is successful, else returns False
        and token set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_auth"
        payload = {
            "username": username,
            "password": password,
            "api_key": api_key
        }
        headers = {
            "Content-Type": "application/json"
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_load(auth_token, filename, options=None):
    """Dataset Upload Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    filename   : type 'str'
        The dataset filename, must be an absolute path
    outcome    : type 'str'
        Outcome column name
    options    : type 'dict'
        A Dictionary of format
        options = {
            "outcome"    : <outcome_column_name|None>
            "id"         : <identifier_column_name|None>,
            "impute"     : <"yes"|"no">,
            "outlier"    : <"yes"|"no">,
            "discard"    : <[list of columns]|None>
            "accelerate" : <"yes"|"no">,
            "shuffle"    : <"yes"|"no">
            }
        Where:
        identifier_column_name : Name of the identifier column.
                                 Machine will discard this column in
                                 model building
        impute                 : Set "yes" if user want to impute
                                 missing column values else set "no"
        outlier                : Set "yes" if user want to remove outliers
                                 else set "no"
        discard                : List of the column names which user want
                                 to discard for model building.
        accelerate             : Set "yes" if user wants machine to upload
                                 the data without impute/outlier/shuffle
                                 options else set "no"
        shuffle                : Set "yes" if user wants to shuffle the rows
                                 in the training data else set "no"

    Returns
    -------
    return_response : type 'dict'
        {
         "success"    : <False|True>,
         "dataset_id" : <None|dataset_id>
        }
        Where:
            success    : True if upload successful else False
            dataset_id : Uploaded file id which would be used in further calls
                         if successful else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_load"
        file_sz_mb = os.path.getsize(filename) >> 20
        if file_sz_mb > 20:
            # df = pd.read_csv(filename, on_bad_lines='skip', index_col=False,
            #                    dtype='unicode')
            df = pd.read_csv(filename, index_col=False, dtype='unicode')
            s_buf = io.BytesIO()
            df.to_parquet(s_buf)
            s_buf.seek(0)
            del df
            files = [("filename", s_buf)]
            options["data_source"] = "parquet"
            options["filename"] = filename.split("/")[-1]
        else:
            files = [("filename", open(filename, "rb"))]
            options["data_source"] = "system"
        payload = {
            "options": json.dumps(options)
        }
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_types(auth_token, dataset_id, options=None):
    """EazyML Type Inference function.
       Returns the type inferred by EazyML on the dataset upload.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The upload dataset ID for which inferred/updated types needs
        to be returned

    Returns
    -------
    return_response : type 'dict'
        {
         "success"   : <False|True>,
         "ez_dtypes" : <None|dataframe_with_dtype>
        }
        Where:
            success   : True if call successful else False
            ez_dtypes : Returns pandas dataframe for supplied dataset id
                        with columns and its dtypes if call successful else
                        set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_types"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_set_outcome(auth_token, dataset_id, outcome, options=None):
    """EazyML Set Outcome function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which outcome needs to be set
    outcome    : type 'str'
        The outcome for the dataset id
    options    : type dict
        A dictionary
            options = {
                "outcome_type" : "categorical/numeric"
            }
    Returns
    -------
    return_response : type 'dict'
        {
         "success" : <False|True>,
         "message" : <appropriate message>
        }
        Where:
            success : True if call successful else False
            message : A message
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_set_outcome"
        payload = {
            "dataset_id": dataset_id,
            "outcome": outcome,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_outlier_detection(auth_token, dataset_id, options=None):
    """EazyML Outlier Detection Function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which outliers needs to be returned

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "outliers"  : <None|outliers_dataframe>
        }
        Where:
            success  : True if call successful else False
            outliers : Returns pandas dataframe for supplied dataset id
                       if outliers detected else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_outlier_detection"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_emptiness(auth_token, dataset_id, options=None):
    """EazyML Data Emptiness Function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which imputed data needs to be returned

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "imputations"  : <None|imputed_dataframe>
        }
        Where:
            success     : True if call successful else False
            imputations : Returns pandas dataframe for supplied dataset id
                          with imputed values else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_emptiness"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_outlier(auth_token, dataset_id, options=None):
    """EazyML Outlier Detection function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which outliers needs to be returned

    Returns
    -------
    return_response : type 'dict'
        {
         "success"  : <False|True>,
         "outliers" : <None|outliers_dataframe>
        }
        Where:
            success  : True if call successful else False
            outliers : Returns pandas dataframe for supplied dataset id with
                       outliers detected if call successful else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_outlier"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_impute(auth_token, dataset_id, options=None):
    """EazyML Imputation function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which imputed data needs to be returned

    Returns
    -------
    return_response : type 'dict'
        {
         "success"     : <False|True>,
         "imputations" : <None|imputed_dataframe>
        }
        Where:
            success     : True if call successful else False
            imputations : Returns pandas dataframe for supplied dataset id
                          with imputed values else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_impute"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_shuffle(auth_token, dataset_id, options=None):
    """EazyML Shuffle function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which imputed data needs to be returned
    options    : type 'dict'
        A Dictionary of format
        options = {
            "shuffle": <"yes"|"no">
            }
        Where:
            shuffle : Set "yes" if user wants to shuffle the rows in the
                      training data else set "no". Default value is "yes".
    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
        }
        Where:
            success     : True if call successful else False
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_shuffle"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_init_model(auth_token, dataset_id, options=None):
    """EazyML Init Model function.

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset ID for which model to be created
    options : type 'dict'
        Configuration to be used while building models
        options = {
             "model_type": <"predictive"|"timeseries">,
             "date_time_column" : <None|time_column_name>,
             "remove_dependent": <"yes"|"no">,
             "derive_numeric": <"yes"|"no">,
             "expressions": <[list of numeric derivations]|None>,
             "derive_text": <"yes"|"no">,
             "text_types": <dict of lists>
             "phrases"   : <dict of lists>
             "accelerate": <"yes"|"no">
         }
        Where:
        accelerate       : Set "yes" if user wants machine to upload the data
                           without derive/remove the columns else set "no"
        model_type       : Set to predictive to build predictive model else
                           build time series model
        date_time_column : Set None if predictive model else specify date time
                           column for time series
        remove_dependent : Set "yes" if user want to remove dependent
                           predictors else set "no"
        derive_numeric   : Set "yes" if user want to derive numeric predictors
                           for model building else set "no"
        expressions      : Set None if user do not want to specify numeric
                           derivations, machine will derive on its own if
                           derive_numeric set to "yes". If user want to derive
                           numeric predictors as per their need user should
                           specify it.
                           Expressions should be of the format '"Column_1"
                           (operator) "Column_2"' where operator can either be
                           '*' (multiply) or '/' (division)
                           For Example:
                           "expressions" : ['"column_1" * "column_2"',
                                            '"column_3" * "column_4"']
        derive_text      : Set "yes" if text column is present and user want to
                           derive text predictors else set "no"
        text_types       : The user can specify the different text types that
                           he wants to derive.
                           Ex: {"col1" : ["sentiments"],
                                "*"    : ["glove", "sentiments",
                                          "concept extraction",
                                          "topic extraction"]}
                           The "*" denotes all other column names. Suppose
                           there are 3 text columns col1, col2, col3, then in
                           this example, for col1 we will derive sentiments
                           and for all the other columns we derive the 4 types
                           mentioned.
        phrases          : The phrases to be used for concept extraction. Only
                           to be specified for those columns for which concept
                           extraction is needed.
                           Ex: {"col1" : ["phrase1", "phrase2"],
                                "*"    : ["phrase3", "phrase4"]}
                           The "*" denotes all other column names. Suppose
                           there are 3 text columns col1, col2, col3, then in
                           this example, for col1 we will use phrases
                           "phrase1", "phrase2" in case the user specifies
                           concept extraction as a type to be derived in text
                           types above and for all the other columns we use
                           phrases "phrase3", "phrase4". This parameter will
                           only come into use if the user specifies concept
                           extraction as a test type for any column.


    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "model_id": <None|integer>,
         "model_performance_df": <None|dataframe>,
         "global_importance_df": <None|dataframe>
        }
        Where:
            success               : True if call successful else False
            model_id              : model_id created for the dataset if
                                    call successful else set to None
            model_performance : Accuracy/Kappa values for the models if
                                accelerate set to "yes" else None
            global_importance : Global importance values if accelerate
                                set to "yes" else None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_init_model"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_remove_dependent(auth_token, model_id, options=None):
    """EazyML Remove Dependent Predictors Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id   : type 'str'
        The model_id created by init_model

    Returns
    -------
    return_response : type 'dict'
        {
         "success"          : <False|True>,
         "features_removed" : list of features that are removed
        }
        Where:
            success          : True if call successful else False
            features_removed : list of features that are removed
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_remove_dependent"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_derive_numeric(auth_token, model_id, options=None):
    """EazyML Numeric Derived Predictor Generation Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id   : type 'str'
        The model_id created by init_model
    options    : type 'dict'
        Configuration to be used while deriving numeric
        options = {
             "expressions"    : <[list of numeric derivations]>
             "return_columns" : <"yes"|"no">,
             "return_dataset" : <"yes"|"no">,
         }
        Where:
        return_columns        : Set "yes" if user wants to return columns only
        return_dataset        : Set "yes" if the user wants to return the
                                dataframe with the added columns. If both are
                                set to "yes", then only columns are returned
        expressions           : Set None if user do not want to specify numeric
                                derivations, machine will derive on its own if
                                derive_numeric set to "yes". If user want to
                                derive numeric predictors as per their need
                                user should specify it.
                                Expressions should be of the format '"Column_1"
                                (operator) "Column_2"' where operator can
                                either be '*' (multiply) or '/' (division)
                               For Example:
                               "expressions" : ['"column_1" * "column_2"',
                                                '"column_3" * "column_4"']

    Returns
    -------
    return_response : type 'dict'
        {
         "success"   : <False|True>,
         "dataframe" : <None|dataframe>
         or
         "columns"   : <list>
        }
        Where:
            success   : True if call successful else False
            dataframe : Pandas dataframe after deriving numeric predictors
                        if return_dataset set to "yes" else None
            columns   : Column names after the predictors are added.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_derive_numeric"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_derive_text(auth_token, model_id, options=None):
    """EazyML Text Derived Predictor Generation Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id   : type 'str'
        The model_id created by init_model
    options    : type 'dict'
        Configuration to be used while deriving text
        options = {
             "text_types"     : <dict of lists>
             "phrases"        : <dict of lists>
             "return_columns" : <"yes"|"no">,
             "return_dataset" : <"yes"|"no">,
         }
        Where:
        return_columns        : Set "yes" if user wants to return columns only
        return_dataset        : Set "yes" if the user wants to return the
                                dataframe with the added columns. If both are
                                set to "yes", then only columns are returned
        text_types            : The user can specify the different text types
                                that he wants to derive.
                                Ex: {"col1" : ["sentiments"],
                                     "*"    : ["glove", "sentiments",
                                               "concept extraction",
                                               "topic extraction"]}
                                The "*" denotes all other column names. Suppose
                                there are 3 text columns col1, col2, col3, then
                                in this example, for col1 we will derive
                                sentiments and for all the other columns we
                                derive the 4 types mentioned.
        phrases               : The phrases to be used for concept extraction.
                                Only to be specified for those columns for
                                which concept extraction is needed.
                                Ex: {"col1" : ["phrase1", "phrase2"],
                                     "*"    : ["phrase3", "phrase4"]}
                                The "*" denotes all other column names. Suppose
                                there are 3 text columns col1, col2, col3, then
                                in this example, for col1 we will use phrases
                                "phrase1", "phrase2" in case the user specifies
                                concept extraction as a type to be derived in
                                text_types above and for all the other columns
                                we use phrases "phrase3", "phrase4". This
                                parameter will only come into use if the user
                                specifies concept extraction as a test type
                                for any column.


    Returns
    -------
    return_response : type 'dict'
        {
         "success"   : <False|True>,
         "dataframe" : <None|dataframe>
         or
         "columns"   : <list>
        }
        Where:
            success   : True if call successful else False
            dataframe : Pandas dataframe after deriving numeric predictors
                        if return_dataset set to "yes" else  None
            columns   : Column names after the predictors are added.

    Note
    -----
    Calling this function would remove the text columns from the dataset, so
    calling this function twice on the same dataset ID and model ID Would
    result in Error.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_derive_text"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_select_features(auth_token, model_id, options=None):
    """EazyML Feature Selection Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by init_model

    Returns
    -------
    return_response : type 'dict'
        {
         "success"  : <False|True>,
         "features" : <None|dataframe>
        }
        Where:
            success  : True if call successful else False
            features : list of selected features
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_select_features"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        print(e)
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_build_models(auth_token, model_id, options=None):
    """EazyML Model Building Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id   : type 'str'
        The model_id created by init_model

    Returns
    -------
    return_response : type 'dict'
        {
         "success"           : <False|True>,
         "model_id"          : <None|integer>,
         "model_performance" : <None|dataframe>,
         "global_importance" : <None|dataframe>
        }
        Where:
            success           : True if call successful else False
            model_id          : model_id created for the dataset if
                                call successful else set to None
            model_performance : Accuracy/Kappa values for the models
            global_importance : Global importance values
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_build_models"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_build_ensemble(auth_token, model_id, ensemble_constituents,
                      options=None):
    """EazyML Ensemble Model Building Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id   : type 'str'
        The model_id created by init_model
    ensemble_constituents : type 'list of str'
            List of models to be included in the ensemble

    Optional Parameters
    -------------------
    ensemble_constituents_weights : list of integers
    Should contain integers specifying the weights of each model
    included in the ensemble

    Returns
    -------
    return_response : type 'dict'
        {
         "success"           : <False|True>,
         "model_id"          : <None|integer>,
         "model_performance" : <None|dataframe>,
         "global_importance" : <None|dataframe>
        }
        Where:
            success           : True if call successful else False
            model_id          : model_id created for the dataset if
                                call successful else set to None
            model_performance : Accuracy/Kappa values for the models
            global_importance : Global importance values
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_build_ensemble"
        payload = {
            "model_id": model_id,
            "ensemble_constituents": ensemble_constituents,
            "options": options,
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }

        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        return exception_return(e, status_code)


def ez_predict(auth_token, model_id, filename, options=None):
    """EazyML Prediction Function

    Parameters
    ----------
    auth_token  : type 'str'
        The auth token generated by ez_auth function
    model_id    : type 'str'
        The model_id created by init_model
    *model_name : type 'str'
        The model name which should be used for prediction
        on prediction dataset file.
        The model name could any of the following for prediction:
          a)Classification Problem:
            "Boosted Decision Trees with InformationGain",
            "Bagged Decision Trees with Information Gain",
            "AdaBoost Decision Trees",
            "Random Forest with Information Gain",
            "Support Vector Machine Classification",
            "K-Nearest Neighbors",
            "Neural Network Classification"
          b)Regression Problem:
            "Bagged Decision Trees"
            "Random Forest"
            "Boosted Decision Trees"
            "Linear Regression"
            "Lasso Regression"
            "Ridge Regression"
            "Support Vector Machine Regression"
            "Neural Network Regression"
        The model name could any of the following for timeseries:
            "FB Prophet"
    filename : type 'str'
        The filename of the prediction dataset. Must be an absolute path

    Returns
    -------
    return_response : type 'dict'
        {
         "success"               : <False|True>,
         "prediction_dataset_id" : <None|integer>,
         "predictions"           : <None|dataframe>
        }
        Where:
            success               : True if call successful else False
            prediction_dataset_id : ID created for uploaded prediction dataset
                                    if call successful else set to None
            predictions           : Dataframe contains all the prediction
                                    dataset rows with an additional column of
                                    predicted values. The additional column
                                    name would be
                                    "predicted_<outcome_column name>"
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_predict"
        payload = {
                "model_id": model_id,
                "options": json.dumps(options)
        }
        files = [("filename", open(filename, "rb"))]
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_explain(auth_token, model_id, prediction_dataset_id, options=None):
    """EazyML Explanation Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by init_model
    prediction_dataset_id : type 'str'
        The prediction dataset ID which should be used for explaining
        the prediction
    record_number : type 'num'
        The record number of prediction dataset for which explanation is needed
        Can also be a list if needed to fetch multiple explanations
        Can also be a comma separated string if needed to fetch multiple
        explanations

    Returns
    -------
    return_response : type 'dict'
        {
         "success"      : <False|True>,
         "explanations" : <None|dict> or <list of dict>
        }
        Where:
            success               : True if call successful else False
            prediction_dataset_id : Returns explanation of the record number.
                                    The explanation dictionary contains:
                                    {
                                     'prediction_dataset_id' :
                                         <prediction_datset_id>,
                                     'explanation' :
                                         <explanation sentence for the
                                         predicted value of the record_number>,
                                     'prediction' :
                                         <predicted_value for the
                                         record_number>,
                                     'local_importance' :
                                         <Importance Dataframe with column name
                                         in order of importance>
                                    }

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_explain"
        payload = {
            "model_id": model_id,
            "prediction_dataset_id": prediction_dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_insert(auth_token, filename, dataset_id, options=None):
    """EazyML Insert function. Override EazyML data preprocessing steps
       using this function.

       Usage: Let your function do some steps using data preprocessing
              EazyML functions. Then you can call the fetch function to
              get the pre processed data from EazyML then perform your
              own preprocessing steps. Now in order to let EazyML know
              of this preprocessing, you should use this function, giving
              the preprocessed dataframe in either csv/xlsx/xls format,
              followed by dataset_id and if applicable, model_id

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    filename : type 'str'
        The filename of the processed dataset. Must be an absolute path
    dataset_id : type 'str'
        The model_id created by ez_load function
    options : type 'dict'
        Options to be used are:
        {
            "model_id" : model_id
        }

    Returns
    -------
    return_response: type 'dict'
        {
         "success" : <False|True>
        }
        Where:
            success : True if call successful else False else set to None
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_insert"
        payload = {
            "dataset_id": dataset_id,
            "options": json.dumps(options)
        }
        files = [("filename", open(filename, "rb"))]
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_drift(auth_token, filename, dataset_id, options=None):
    """EazyML data drift function

       Usage: Drift is responsible to test the distributional and model drift
              of (train,test) data in EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset_id created by ez_load function
    filename : type 'str'
        The path of test data file
    options : type 'dict'
        Configuration to be used while fetching dataframe
        options = {
             "model_drift": <"yes"|"no">,
             "data_drift": <"yes"|"no">,
         }

    Returns
    -------
    return_response : type 'dict'
        {
         "success": <False|True>,
         "drift": <None|json output of drift>,
        }
        Where:
            success : True if call successful else False
            drift   : A dictionary with the key drift analysis

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_drift"
        payload = {
            "dataset_id": dataset_id,
            "options": json.dumps(options)
        }
        files = [("filename", open(filename, "rb"))]
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers,
            data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_balance(auth_token, dataset_id, options=None):
    """EazyML data balance function

       Usage: data balance is responsible to test the
              data imbalance for classification type
              of problems in EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset_id created by ez_load function
    options : type 'dict'
        options = {}

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "data_balance": <None|json output of drift>,
        }
        Where:
            success              : True if call successful else False
            data balance         : A dictionary with the key data balance
                                   analysis
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_balance"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_config(auth_token, filename, options=None):
    """EazyML Configuration function.

       Can be used to override EazyML defaults which are used internally
       For example:
           In the remove dependent predictors, You can increase the threshold
           used by VIF by making an ini file with VIF_THRESHOLD = 100 for e.g.
           and passing the ini file, dataset_id and model_id in this function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    filename: type 'str'
        The path to valid config file, which is of ini format. The config file
        should have section 'UPLOAD_DATA and if model_id is passed then it
        should have section 'BUILD_MODEL' and if prediction_dataset_id
        is passed, it should have 'TEST_MODEL' section.
    options : type 'dict'
        Configuration to be used:
        options = {
             "prediction_dataset_id": prediction_dataset_id,
             "dataset_id" : dataset_id
             "model_id" : model_id
         }

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
        }
        Where:
            success              : True if call successful else False
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_config"
        payload = {
            "options": json.dumps(options)
        }
        files = [("filename", open(filename, "rb"))]
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_get_model_status(auth_token, model_id, options=None):
    """EazyML model status fetch function

       Usage: gets the status of a model_id from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by ez_init function
    options : type 'dict'
        Configuration to be used while getting model status
        options = {
             "return_models": <"yes"|"no">
         }

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Model status message>,
         or
         "models" : <dict of models if built>
        }
        Where:
            success              : True if call successful else False
            message              : Model status message.
            models               : A dictionary with the models data
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_get_model_status"
        payload = {
            "model_id": model_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_get_datasets(auth_token, options=None):
    """EazyML training datasets fetch function

       Usage: gets all of your training datasets from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>,
         "dataframe": <dict of datasets>
        }
        Where:
            success              : True if call successful else False
            message              : Model status message.
            dataframe            : A dictionary of the datasets
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_get_datasets"
        payload = {
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_get_test_datasets(auth_token, options=None):
    """EazyML test datasets fetch function

       Usage: gets all of your test datasets from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>,
         "dataframe": <dict of datasets>
        }
        Where:
            success              : True if call successful else False
            message              : Model status message.
            dataframe            : A dictionary of the datasets
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_get_test_datasets"
        payload = {
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_get_models(auth_token, options=None):
    """EazyML models fetch function

       Usage: gets all of your models from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>,
         "dataframe": <dict of datasets>
        }
        Where:
            success              : True if call successful else False
            message              : Model status message.
            dataframe            : A dictionary of the datasets
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_get_models"
        payload = {
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_delete_datasets(auth_token, dataset_id):
    """EazyML training datasets delete function

       Usage: deletes training datasets from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : Dataset to be deleted
    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>
        }
        Where:
            success              : True if call successful else False
            message              : Delete status message.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_delete_datasets"
        payload = {
            "dataset_id": dataset_id
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_delete_test_datasets(auth_token, prediction_dataset_id):
    """EazyML training test datasets delete function

       Usage: deletes prediction datasets from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    prediction_dataset_id : Prediction dataset to be deleted
    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>
        }
        Where:
            success              : True if call successful else False
            message              : Delete status message.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_delete_test_datasets"
        payload = {
            "prediction_dataset_id": prediction_dataset_id
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_delete_models(auth_token, model_id):
    """EazyML models delete function

       Usage: ez_delete_models function deletes models from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : Model to be deleted
    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "message": <Fetch status message>
        }
        Where:
            success              : True if call successful else False
            message              : Delete status message.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_delete_models"
        payload = {
            "model_id": model_id
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_export_model(auth_token, model_id, model_name, options=None):
    """EazyML Model Building Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by init_model
    model_name : type 'str'
        The model_name for which zip file is to be exported.

    Returns
    -------
    return_response: type 'dict'
        {
         "message": <str>
        }
        and a zip file containing the model.
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_export_model"
        payload = {
                "model_id": model_id,
                "model_name": model_name,
                "options": options
        }

        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }

        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        response_json = {}
        try:
            response_json = response.json()
            return response_json
        except Exception as e:
            print(e)
            response.raise_for_status()
        try:
            filename = model_name.replace("/n", "_") + ".zip"
            handle = open(filename, "wb")
            for chunk in response.iter_content(chunk_size=512):
                if chunk:
                    handle.write(chunk)
            handle.close()
            return {'message': "The model has been exported to a file" +
                               "with name '{0}' and is downloaded successfully"
                               .format(filename),
                    'status code': status_code}
        except Exception as e:
            print(e)
            response.raise_for_status()
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_validate(auth_token, model_id, options=None):
    """EazyML Validation Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by init_model
    filename : type 'str'
            The filename of the prediction dataset. Must be an absolute path
    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "validation_dataset_id": <None|integer>,
         "validated_datatable": <None|dataframe>
        }
        Where:
            success         : True if call successful else False
            validation_dataset_id: ID created for uploaded prediction dataset
                                   if call successful else set to None
            validated_datatable: A Pandas Dataframe in JSON format.
                                 The JSON contains two keys:
                                  data: the data in list of list format
                                  columns: The columns of the dataframe in list
                                           format which will show validation
                                           scores

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_validate"
        if "filename" in options:
            filename = options["filename"]
            files = [("filename", open(filename, "rb"))]
            del(options["filename"])
        else:
            files = []
        payload = {
                "model_id": model_id,
                "options": json.dumps(options)
        }
        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers,
            data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_explain_validation(auth_token, model_id, validation_dataset_id,
                          options=None):
    """EazyML Validation Function

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    model_id : type 'str'
        The model_id created by init_model
    validation_dataset_id : type 'str'
        The validation dataset ID which should be used for explaining the
        prediction
    record_number : type 'num'
        The record number of Augmented Intelligence dataframe for which
        validation is needed. Can also be a list if needed to fetch
        multiple validations. Can also be a comma separated string if
        needed to fetch multiple validations

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "validations": <None|dict> or <list of dict>
        }
        Where:
            success         : True if call successful else False
            validations: Returns validations of the record numbers.
                         The validation dictionary contains:
                {
                 'rule_string': <rule of augmented intelligence>,
                 'filtered_data': <test data filtered by the rule,
                 'Train Score': <confidence score on the train data>,
                 ...: <other scores based on config params set like
                       accuracy, coverage, perception, etc.>
                }

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_explain_validation"
        payload = {
            "model_id": model_id,
            "validation_dataset_id": validation_dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL,
            headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_fetch(auth_token, dataset_id, options=None):
    """EazyML Pre-processed data fetch function

       Usage: fetch function gets the pre processed data from EazyML

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset_id created by ez_load function
    options : type 'dict'
        Configuration to be used while fetching dataframe
        options = {
             "return_columns": <"yes"|"no">,
             "return_dataset": <"yes"|"no">,
             "model_id" : model_id
         }

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "dataframe": <None|dataframe>,
         or
         "columns" : <list of columns>
        }
        Where:
            success              : True if call successful else False
            dataframe            : A dictionary with the keys columns,
                                   index and data
            columns              : list of columns
    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_fetch"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)


def ez_shape(auth_token, dataset_id, options=None):
    """EazyML shape function

       Usage: shape is responsible to test the vaild data size in EazyML
    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset_id created by ez_load function
    options : type 'dict'
        options = {
         }

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "dataset_shape": <None|json output of data shape>,
        }
        Where:
            success      : True if call successful else False
            dataset_shape: A dictionary with the key dataset shape

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_shape"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }

        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        print((traceback.print_exc()))
        return exception_return(e, status_code)


def ez_correlation(auth_token, dataset_id, options=None):
    """EazyML output correlation function

       Usage: ez_correlation is responsible to test the correlation between
              outcome and other features

    Parameters
    ----------
    auth_token : type 'str'
        The auth token generated by ez_auth function
    dataset_id : type 'str'
        The dataset_id created by ez_load function
    options : type 'dict'
        options = {

         }

    Returns
    -------
    return_response: type 'dict'
        {
         "success": <False|True>,
         "data_balance": <None|json output of correlation>,
        }
        Where:
            success           : True if call successful else False
            output correlation: A dictionary with the key output correlation

    """
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_correlation"
        payload = {
            "dataset_id": dataset_id,
            "options": options
        }

        headers = {
            "Authorization": "Bearer " + str(auth_token),
        }
        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=json.dumps(payload)
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        print((traceback.print_exc()))
        return exception_return(e, status_code)


def ez_data_quality(auth_token, train_filename, outcome, options=None):
    status_code = 500
    try:
        API_REQUEST_URL = API_URL + "/ez_data_quality"
        files = [("filename", open(train_filename, "rb"))]
        if options and "prediction_filename" in options and \
           options["prediction_filename"]:
            prediction_filename = options["prediction_filename"]
            files.append(("prediction_filename",
                          open(prediction_filename, "rb")))
            del(options["prediction_filename"])

        payload = {
            "outcome": outcome,
            "options": json.dumps(options)
        }

        headers = {
            "Authorization": "Bearer " + str(auth_token)
        }

        response = requests.request(
            "POST", API_REQUEST_URL, headers=headers, data=payload, files=files
        )
        status_code = response.status_code
        try:
            response_json = response.json()
        except Exception as e:
            print(e)
            response.raise_for_status()
        response_json["status_code"] = status_code
        return response_json
    except Exception as e:
        traceback.print_exc()
        return exception_return(e, status_code)
